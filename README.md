# ğŸš€ IsCoolGPT - API com Suporte a Gemini

Uma API FastAPI que funciona como adaptador para diferentes provedores de IA (OpenAI, Gemini, Mock).

## ğŸ“‹ O que Ã© este projeto?

- **Framework**: FastAPI
- **PropÃ³sito**: API REST que integra diferentes provedores de IA
- **Endpoint Principal**: `POST /v1/ask` - recebe prompt e retorna resposta da IA

## ğŸ”§ Como funciona?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Request   â”‚
â”‚  (prompt)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   IsCoolService      â”‚
â”‚  (lÃ³gica central)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    LLM Adapter (Factory)    â”‚
â”‚  - MockLLM                  â”‚
â”‚  - OpenAIProvider           â”‚
â”‚  - GeminiProvider âœ¨ (NOVO) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           v
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   API   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Como usar Gemini API

### Passo 1: Obter a API Key do Gemini

1. Acesse: https://ai.google.dev
2. Clique em "Get API key"
3. Crie um novo projeto no Google Cloud Console
4. Crie uma nova chave de API
5. Copie a chave

### Passo 2: Configurar VariÃ¡veis de Ambiente

```bash
# Copie o arquivo exemplo
cp .env.example .env

# Edite o arquivo .env e adicione:
LLM_PROVIDER=gemini
GEMINI_API_KEY=sua_chave_gemini_aqui
```

### Passo 3: Instalar DependÃªncias

```bash
# Criar ambiente virtual (recomendado)
python -m venv venv

# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### Passo 4: Executar Localmente

```bash
# Modo desenvolvimento (com reload automÃ¡tico)
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Modo produÃ§Ã£o
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000
```

A API estarÃ¡ disponÃ­vel em: **http://localhost:8000**

## ğŸ“¡ Testar a API

### Exemplo de Request:

```bash
curl -X POST "http://localhost:8000/v1/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "user123",
    "prompt": "O que Ã© uma IA?"
  }'
```

### Resposta esperada:

```json
{
  "reply": "Uma InteligÃªncia Artificial (IA) Ã© um sistema computacional...",
  "model": "GeminiProvider"
}
```

## ğŸ³ Com Docker

### Build:

```bash
docker build -t iscoolGpt .
```

### Run:

```bash
docker run -e GEMINI_API_KEY="sua_chave_aqui" \
           -e LLM_PROVIDER="gemini" \
           -p 8000:8000 \
           iscoolGpt
```

### Com Docker Compose:

```yaml
# docker-compose.yml
version: '3.8'
services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      LLM_PROVIDER: gemini
      GEMINI_API_KEY: ${GEMINI_API_KEY}
```

```bash
# Executar
export GEMINI_API_KEY="sua_chave_aqui"
docker-compose up
```

## âš™ï¸ OpÃ§Ãµes de Providers

### 1ï¸âƒ£ Mock (PadrÃ£o - para testes)
```
LLM_PROVIDER=mock
```
NÃ£o requer API key, Ãºtil para testes e desenvolvimento.

### 2ï¸âƒ£ OpenAI
```
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-...
```

### 3ï¸âƒ£ Gemini (Recomendado) âœ¨
```
LLM_PROVIDER=gemini
GEMINI_API_KEY=AIza...
```

## ğŸ“ Estrutura do Projeto

```
app/
â”œâ”€â”€ main.py              # Entry point FastAPI
â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes (env vars)
â”œâ”€â”€ schemas.py           # Modelos Pydantic
â”œâ”€â”€ api/
â”‚   â””â”€â”€ v1.py           # Rotas da API
â””â”€â”€ services/
    â”œâ”€â”€ iscool_service.py      # LÃ³gica da aplicaÃ§Ã£o
    â””â”€â”€ llm_adapter.py         # Providers de IA (MODIFICADO)
```

## ğŸ§ª Testes

```bash
# Executar testes
pytest test/

# Com cobertura
pytest --cov=app test/
```

## ğŸ“ Arquivos Modificados

- âœ… `requirements.txt` - Adicionado `google-generativeai`
- âœ… `app/config.py` - Adicionado `GEMINI_API_KEY`
- âœ… `app/services/llm_adapter.py` - Adicionado `GeminiProvider`
- âœ… `.env.example` - InstruÃ§Ãµes para Gemini

## ğŸš¨ Troubleshooting

### Erro: "Gemini API key not configured"
- Verifique se `GEMINI_API_KEY` estÃ¡ definida em `.env`
- Verifique se `LLM_PROVIDER=gemini`

### Erro: "ModuleNotFoundError: No module named 'google'"
- Execute: `pip install -r requirements.txt`

### Erro de Rate Limit do Gemini
- Aguarde alguns segundos e tente novamente
- Consulte limites em: https://ai.google.dev/pricing

## ğŸ“š Recursos Ãšteis

- [DocumentaÃ§Ã£o Gemini API](https://ai.google.dev/docs)
- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [Pydantic Docs](https://docs.pydantic.dev/)

---

**Autor**: Seu Nome  
**Data**: Novembro 2025  
**Status**: âœ… Funcionando com Gemini API
